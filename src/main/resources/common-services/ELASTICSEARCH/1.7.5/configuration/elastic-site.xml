<?xml version="1.0"?>
<?xml-stylesheet type="text/xsl" href="configuration.xsl"?>
<!--
  Licensed to the Apache Software Foundation (ASF) under one
  or more contributor license agreements.  See the NOTICE file
  distributed with this work for additional information
  regarding copyright ownership.  The ASF licenses this file
  to you under the Apache License, Version 2.0 (the
  "License"); you may not use this file except in compliance
  with the License.  You may obtain a copy of the License at

       http://www.apache.org/licenses/LICENSE-2.0

  Unless required by applicable law or agreed to in writing, software
  distributed under the License is distributed on an "AS IS" BASIS,
  WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
  See the License for the specific language governing permissions and
  limitations under the License.
-->
<!-- Elastic search  Configurations -->

<configuration supports_final="true">
    <!-- Configurations -->
    <property>
        <name>cluster_name</name>
        <value>metron</value>
        <description>Elasticsearch Cluster Name identifies your Elasticsearch subsystem</description>
    </property>
    <property>
        <name>masters_also_are_datanodes</name>
        <value>"false"</value>
        <description>ES Masters and Slaves cannot be installed on the same nodes.  Set this to "true" if you want the ES master nodes to serve as combined master/datanodes. Note: surround value in quotes.</description>
        <value-attributes>
            <type>string</type>
        </value-attributes>
    </property>
    <property>
        <name>zen_discovery_ping_unicast_hosts</name>
        <!--Ideally this gets populated by the list of master eligible nodes (as an acceptable default).  Unsure how to do this.-->
        <!--Also need to document whether should list masters only, or all ES nodes. I think this one is all nodes, but previous inline comment said Masters.-->
        <value></value>
        <description>Unicast discovery list of hosts to act as gossip routers, comma-separated list with square brackets: [ eshost1, eshost2 ]</description>
    </property>
    <property>
        <name>index_number_of_shards</name>
        <value>4</value>
        <description>Set the number of shards (splits) of an index.  Changes are not effective after index creation. Usually set to 1 for single-node install.</description>
    </property>
    <property>
        <name>index_number_of_replicas</name>
        <value>2</value>
        <description>Set the number of replicas (copies in addition to the first) of an index. Usually set to 0 for single-node install.</description>
    </property>
    <property>
        <name>path_data</name>
        <value>"/opt/lmm/es_data"</value>
        <description>Comma-separated list of directories where to store index data allocated for each node: "/mnt/first","/mnt/second".  Number of paths should relate to number of shards, and preferably should be on separate physical volumes.</description>
    </property>
    <property>
        <name>http_cors_enabled</name>
        <value>"false"</value>
        <description>Enable or disable cross-origin resource sharing, i.e. whether a browser on another origin can do requests to Elasticsearch. Defaults to false.</description>
        <value-attributes>
            <type>string</type>
        </value-attributes>
    </property>
    <property>
        <name>http_port</name>
        <value>9200-9300</value>
        <description>Set a custom port to listen for HTTP traffic</description>
    </property>
    <property>
        <name>transport_tcp_port</name>
        <value>9300-9400</value>
        <description>Set a custom port for the node to node communication</description>
    </property>
    <!--  Multi-node Discovery -->
    <property>
        <name>discovery_zen_ping_multicast_enabled</name>
        <value>false</value>
        <description>Whether to use multicast</description>
    </property>
    <property>
        <name>discovery_zen_ping_timeout</name>
        <value>3s</value>
        <description>Wait for ping responses for master discovery</description>
    </property>
    <property>
        <name>discovery_zen_fd_ping_interval</name>
        <value>15s</value>
        <description>Wait for ping for cluster discovery</description>
    </property>
    <property>
        <name>discovery_zen_fd_ping_timeout</name>
        <value>60s</value>
        <description>Wait for ping for cluster discovery</description>
    </property>
    <property>
        <name>discovery_zen_fd_ping_retries</name>
        <value>5</value>
        <description>Number of ping retries before blacklisting</description>
    </property>
    <!--  Gateway -->
    <property>
        <name>gateway_recover_after_data_nodes</name>
        <value>3</value>
        <description>Recover as long as this many data or master nodes have joined the cluster.</description>
    </property>
    <property>
        <name>recover_after_time</name>
        <value>15m</value>
        <description>recover_after_time</description>
    </property>
    <property>
        <name>expected_data_nodes</name>
        <value>0</value>
        <description>expected_data_nodes</description>
    </property>
    <!--  Index -->  
    <property>
        <name>index_merge_scheduler_max_thread_count</name>
        <value>5</value>
        <description>index.merge.scheduler.max_thread_count</description>
    </property>
    <property>
        <name>indices_memory_index_store_throttle_type</name>
        <value>none</value>
        <description>index_store_throttle_type</description>
    </property>
    <property>
        <name>index_refresh_interval</name>
        <value>1s</value>
        <description>index refresh interval</description>
    </property>
    <property>
        <name>index_translog_flush_threshold_size</name>
        <value>5g</value>
        <description>index_translog_flush_threshold_size</description>
    </property>
    <property>
        <name>indices_memory_index_buffer_size</name>
        <value>10%</value>
        <description>Percentage of heap used for write buffers</description>
    </property>
    <property>
        <name>bootstrap_mlockall</name>
        <value>true</value>
        <description>The third option on Linux/Unix systems only, is to use mlockall to try to lock the process address space into RAM, preventing any Elasticsearch memory from being swapped out</description>
    </property>
    <property>
        <name>threadpool_bulk_queue_size</name>
        <value>3000</value>
        <description>It tells ES the number of  requests that can be queued for execution in the node when there is no thread available to execute a bulk request</description>
    </property>
    <property>
        <name>threadpool_index_queue_size</name>
        <value>1000</value>
        <description>It tells ES the number of  requests that can be queued for execution in the node when there is no thread available to execute index request</description>
    </property>
    <property>
        <name>indices_cluster_send_refresh_mapping</name>
        <value>false</value>
        <description>In order to make the index request more efficient, we have set this property on our data nodes</description>
    </property>
    <property>
        <name>indices_fielddata_cache_size</name>
        <value>25%</value>
        <description>You need to keep in mind that not setting this value properly can cause:Facet searches and sorting to have very poor performance:The ES node to run out of memory if you run the facet query against a large index</description>
    </property>
    <property>
        <name>cluster_routing_allocation_disk_watermark_high</name>
        <value>0.99</value>
        <description>Property used when multiple drives are used to understand max thresholds</description>
    </property>
    <property>
        <name>cluster_routing_allocation_disk_threshold_enabled</name>
        <value>true</value>
        <description>Property used when multiple drives are used to understand if thresholding is active</description>
    </property>   
   <property>
        <name>cluster_routing_allocation_disk_watermark_low</name>
        <value>.97</value>
        <description>Property used when multiple drives are used to understand min thresholds</description>
    </property>
    <property>
        <name>cluster_routing_allocation_node_concurrent_recoveries</name>
        <value>4</value>
        <description>Max concurrent recoveries, useful for fast recovery of the cluster nodes on restart</description>
    </property>
    <property>
        <name>network_host</name>
        <value>[ _local_, _site_ ]</value>
        <description>Network interface(s) ES will bind to within each node. "_site_" or a more specific external address is required for all multi-node clusters, and also recommended for single-node installs to allow access to ES reports from non-local hosts. Always include the square brackets. See https://www.elastic.co/guide/en/elasticsearch/reference/2.3/modules-network.html for ES documentation.</description>
    </property>
    <property>
        <name>network_publish_host</name>
        <value></value>
        <value-attributes>
            <empty-value-valid>true</empty-value-valid>
        </value-attributes>
        <description>Network address ES will publish for client and peer use. Empty value causes it to pick from the values in network_host, which works in most simple environments. MUST set explicitly for MULTI-HOMED SYSTEMS. See https://www.elastic.co/guide/en/elasticsearch/reference/2.3/modules-network.html for ES documentation.</description>
    </property>
</configuration>
